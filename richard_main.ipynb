{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "# from model import RW_NN\n",
    "from utils import load_data, generate_batches, accuracy, AverageMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "from types import SimpleNamespace\n",
    "args = SimpleNamespace(\n",
    "    dataset='synthetic',\n",
    "    use_node_labels=False,\n",
    "    lr=1e-2,\n",
    "    dropout=0.2,\n",
    "    batch_size=64,\n",
    "    epochs=5,\n",
    "    hidden_graphs=16,\n",
    "    size_hidden_graphs=5,\n",
    "    hidden_dim=4,\n",
    "    penultimate_dim=32,\n",
    "    max_step=2,\n",
    "    normalize=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_lst, features_lst, class_labels = load_data(args.dataset, args.use_node_labels)\n",
    "\n",
    "N = len(adj_lst)\n",
    "features_dim = features_lst[0].shape[1]\n",
    "\n",
    "enc = LabelEncoder()\n",
    "class_labels = enc.fit_transform(class_labels)\n",
    "n_classes = np.unique(class_labels).size\n",
    "y = [np.array(class_labels[i]) for i in range(class_labels.size)]\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=13)\n",
    "it = 0\n",
    "accs = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE MODEL\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import networkx as nx\n",
    "from input_data import load_data\n",
    "from preprocessing import preprocess_graph\n",
    "import vgae_model\n",
    "from types import SimpleNamespace\n",
    "\n",
    "vgae_args = SimpleNamespace(\n",
    "    ### CONFIGS ###\n",
    "    model = 'VGAE',\n",
    "    input_dim = 5, \n",
    "    hidden1_dim = 4,\n",
    "    hidden2_dim = 4,\n",
    "    use_feature = True,\n",
    "    num_epoch = 200,\n",
    "    learning_rate = 0.01\n",
    ")\n",
    "\n",
    "class RW_NN(nn.Module):\n",
    "    # new hyperparameters\n",
    "    # max_num_children\n",
    "    def __init__(self, input_dim, max_step, hidden_graphs, size_hidden_graphs, hidden_dim, penultimate_dim, normalize, n_classes, dropout, device):\n",
    "        super(RW_NN, self).__init__()\n",
    "        self.max_step = max_step\n",
    "        self.hidden_graphs = hidden_graphs\n",
    "        self.size_hidden_graphs = size_hidden_graphs\n",
    "        self.normalize = normalize\n",
    "        self.device = device\n",
    "\n",
    "        self.adj_hidden = Parameter(torch.FloatTensor(hidden_graphs, (size_hidden_graphs*(size_hidden_graphs-1))//2))\n",
    "        self.adj_hidden_tree = None\n",
    "        self.adj_hidden_tree_norm = None\n",
    "        self.features_hidden = Parameter(torch.FloatTensor(hidden_graphs, size_hidden_graphs, hidden_dim))\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.features_hidden_tree = None\n",
    "        self.input_dim = input_dim\n",
    "        self.penultimate_dim = penultimate_dim\n",
    "\n",
    "        self.fc = torch.nn.Linear(input_dim, hidden_dim)\n",
    "        self.bn = nn.BatchNorm1d(hidden_graphs*max_step)\n",
    "        self.fc1 = torch.nn.Linear(hidden_graphs*max_step, penultimate_dim)\n",
    "        self.fc2 = torch.nn.Linear(penultimate_dim, n_classes)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.adj_hidden.data.uniform_(-1, 1)\n",
    "        self.features_hidden.data.uniform_(0, 1)\n",
    "\n",
    "        \n",
    "    def forward(self, adj, features, graph_indicator, y=None):\n",
    "        if self.training:            \n",
    "            self.fc = torch.nn.Linear(self.input_dim, self.hidden_dim)\n",
    "            self.bn = nn.BatchNorm1d(self.hidden_graphs*self.max_step)\n",
    "            self.fc1 = torch.nn.Linear(self.hidden_graphs*self.max_step, self.penultimate_dim)\n",
    "            self.fc2 = torch.nn.Linear(self.penultimate_dim, n_classes)\n",
    "            unique, counts = torch.unique(graph_indicator, return_counts=True)\n",
    "            n_graphs = unique.size(0)\n",
    "            n_nodes = features.size(0)\n",
    "\n",
    "            if self.normalize:\n",
    "                norm = counts.unsqueeze(1).repeat(1, self.hidden_graphs)\n",
    "            \n",
    "            adj_hidden_norm = torch.zeros(self.hidden_graphs, self.size_hidden_graphs, self.size_hidden_graphs).to(self.device)\n",
    "            idx = torch.triu_indices(self.size_hidden_graphs, self.size_hidden_graphs, 1)\n",
    "            adj_hidden_norm[:,idx[0],idx[1]] = self.relu(self.adj_hidden)\n",
    "            adj_hidden_norm = adj_hidden_norm + torch.transpose(adj_hidden_norm, 1, 2)\n",
    "            x = self.sigmoid(self.fc(features))\n",
    "            z = self.features_hidden\n",
    "            zx = torch.einsum(\"abc,dc->abd\", (z, x))\n",
    "            \n",
    "            out = list()\n",
    "            for i in range(self.max_step):\n",
    "                if i == 0:\n",
    "                    eye = torch.eye(self.size_hidden_graphs, device=self.device)\n",
    "                    eye = eye.repeat(self.hidden_graphs, 1, 1)              \n",
    "                    o = torch.einsum(\"abc,acd->abd\", (eye, z))\n",
    "                    t = torch.einsum(\"abc,dc->abd\", (o, x))\n",
    "                else:\n",
    "                    x = torch.spmm(adj, x)\n",
    "                    z = torch.einsum(\"abc,acd->abd\", (adj_hidden_norm, z))\n",
    "                    t = torch.einsum(\"abc,dc->abd\", (z, x))\n",
    "                t = self.dropout(t)\n",
    "                t = torch.mul(zx, t)\n",
    "                t = torch.zeros(t.size(0), t.size(1), n_graphs, device=self.device).index_add_(2, graph_indicator, t)\n",
    "                t = torch.sum(t, dim=1)\n",
    "                t = torch.transpose(t, 0, 1)\n",
    "                if self.normalize:\n",
    "                    t /= norm\n",
    "                out.append(t)\n",
    "                \n",
    "            out = torch.cat(out, dim=1)\n",
    "            out = self.bn(out)\n",
    "            out = self.relu(self.fc1(out))\n",
    "            out = self.dropout(out)\n",
    "            out = self.fc2(out)\n",
    "            return F.log_softmax(out, dim=1)\n",
    "        else:\n",
    "            adj_hidden_vgae, vgae_features = self.run_vgae()\n",
    "            self.fc = torch.nn.Linear(self.input_dim, self.hidden_dim)\n",
    "            self.bn = nn.BatchNorm1d(2)\n",
    "            self.fc1 = torch.nn.Linear(self.max_step, self.penultimate_dim)\n",
    "            self.fc2 = torch.nn.Linear(self.penultimate_dim, n_classes)\n",
    "            unique, counts = torch.unique(graph_indicator, return_counts=True)\n",
    "            n_graphs = unique.size(0)\n",
    "            n_nodes = features.size(0)\n",
    "\n",
    "            if self.normalize:\n",
    "                norm = counts.unsqueeze(1).repeat(1, self.hidden_graphs)\n",
    "            \n",
    "            # 1 hidden graph\n",
    "            adj_hidden_norm = torch.zeros(1, self.size_hidden_graphs, self.size_hidden_graphs).to(self.device)\n",
    "            idx = torch.triu_indices(self.size_hidden_graphs, self.size_hidden_graphs, 1)\n",
    "            adj_hidden_norm[:,idx[0],idx[1]] = self.relu(adj_hidden_vgae)\n",
    "            adj_hidden_norm = adj_hidden_norm + torch.transpose(adj_hidden_norm, 1, 2)\n",
    "            print(\"FEATURE SHAPE\", features.shape)\n",
    "            x = self.sigmoid(self.fc(features))\n",
    "            z = vgae_features.unsqueeze(0)\n",
    "            zx = torch.einsum(\"abc,dc->abd\", (z, x))\n",
    "            \n",
    "            out = list()\n",
    "            for i in range(self.max_step):\n",
    "                if i == 0:\n",
    "                    eye = torch.eye(self.size_hidden_graphs, device=self.device)\n",
    "                    eye = eye.repeat(1, 1, 1)              \n",
    "                    o = torch.einsum(\"abc,acd->abd\", (eye, z))\n",
    "                    t = torch.einsum(\"abc,dc->abd\", (o, x))\n",
    "                else:\n",
    "                    x = torch.spmm(adj, x)\n",
    "                    z = torch.einsum(\"abc,acd->abd\", (adj_hidden_norm, z))\n",
    "                    t = torch.einsum(\"abc,dc->abd\", (z, x))\n",
    "                t = self.dropout(t)\n",
    "                t = torch.mul(zx, t)\n",
    "                t = torch.zeros(t.size(0), t.size(1), n_graphs, device=self.device).index_add_(2, graph_indicator, t)\n",
    "                t = torch.sum(t, dim=1)\n",
    "                t = torch.transpose(t, 0, 1)\n",
    "                if self.normalize:\n",
    "                    t /= norm\n",
    "                out.append(t)\n",
    "                \n",
    "            out = torch.cat(out, dim=1)\n",
    "            out = self.bn(out)\n",
    "            out = self.relu(self.fc1(out))\n",
    "            out = self.dropout(out)\n",
    "            out = self.fc2(out)\n",
    "            return F.log_softmax(out, dim=1)\n",
    "        \n",
    "\n",
    "    \n",
    "    def get_hidden_graphs_adjacency_list(self):\n",
    "        \"\"\"Converts the upper-triangular adjacency data to adjacency lists.\"\"\"\n",
    "        adj_hidden_norm = torch.zeros(self.hidden_graphs, self.size_hidden_graphs, self.size_hidden_graphs).to(self.device)\n",
    "        idx = torch.triu_indices(self.size_hidden_graphs, self.size_hidden_graphs, 1)\n",
    "        adj_hidden_norm[:, idx[0], idx[1]] = self.relu(self.adj_hidden)\n",
    "        adj_hidden_norm = adj_hidden_norm + torch.transpose(adj_hidden_norm, 1, 2)\n",
    "        \n",
    "        # Convert each hidden graph's adjacency matrix to an adjacency list\n",
    "        adjacency_lists = []\n",
    "        for i in range(self.hidden_graphs):\n",
    "            adj_list = {}\n",
    "            adj_matrix = adj_hidden_norm[i].detach().cpu().numpy()  # Move to CPU for easy processing\n",
    "            for row in range(adj_matrix.shape[0]):\n",
    "                adj_list[row] = list(np.where(adj_matrix[row] > 0)[0])  # Find connected nodes\n",
    "            adjacency_lists.append(adj_list)\n",
    "        \n",
    "        return adjacency_lists\n",
    "    \n",
    "\n",
    "\n",
    "# VGAE METHODS\n",
    "    def sparse_to_tuple(self, sparse_mx):\n",
    "        if not sp.isspmatrix_coo(sparse_mx):\n",
    "            sparse_mx = sparse_mx.tocoo()\n",
    "        coords = np.vstack((sparse_mx.row, sparse_mx.col)).transpose()\n",
    "        values = sparse_mx.data\n",
    "        shape = sparse_mx.shape\n",
    "        return coords, values, shape\n",
    "    def mask_test_edges(self, adj):\n",
    "        adj = adj - sp.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape)\n",
    "        adj.eliminate_zeros()\n",
    "\n",
    "        adj_triu = sp.triu(adj)\n",
    "        adj_tuple = self.sparse_to_tuple(adj_triu)\n",
    "        edges = adj_tuple[0]\n",
    "\n",
    "        num_edges = edges.shape[0]\n",
    "        if num_edges < 10:\n",
    "            print(\"Not enough edges for a split. Using all edges for training.\")\n",
    "            return edges, [], []  # Return all edges for training, no validation/test\n",
    "\n",
    "        num_test = int(np.floor(num_edges / 10.))\n",
    "        num_val = int(np.floor(num_edges / 20.))\n",
    "\n",
    "        all_edge_idx = list(range(num_edges))\n",
    "        np.random.shuffle(all_edge_idx)\n",
    "        val_edge_idx = all_edge_idx[:num_val]\n",
    "        test_edge_idx = all_edge_idx[num_val:(num_val + num_test)]\n",
    "\n",
    "        test_edges = edges[test_edge_idx] if test_edge_idx else []\n",
    "        val_edges = edges[val_edge_idx] if val_edge_idx else []\n",
    "        train_edges = np.delete(edges, np.hstack([test_edge_idx, val_edge_idx]), axis=0)\n",
    "\n",
    "        return train_edges, val_edges, test_edges\n",
    "    def get_acc(self, adj_rec, adj_label):\n",
    "        labels_all = adj_label.to_dense().view(-1).long()\n",
    "        preds_all = (adj_rec > 0.5).view(-1).long()\n",
    "        accuracy = (preds_all == labels_all).sum().float() / labels_all.size(0)\n",
    "        return accuracy\n",
    "    def run_vgae(self):\n",
    "        adjacency_lists = self.get_hidden_graphs_adjacency_list()\n",
    "        # Train on CPU (hide GPU) due to memory constraints\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = \"\"\n",
    "\n",
    "        # Get adjacency lists from model\n",
    "        # Create graph from the first hidden graph's adjacency list\n",
    "        # DO IT ON ONLY THE FIRST HIDDEN GRAPH\n",
    "        graph = nx.from_dict_of_lists(adjacency_lists[0])\n",
    "\n",
    "        # Convert graph to adjacency matrix\n",
    "        adj = nx.adjacency_matrix(graph)\n",
    "\n",
    "        # Check if adj is a PyTorch tensor and convert it to scipy sparse matrix\n",
    "        if isinstance(adj, torch.Tensor):\n",
    "            adj = adj.cpu().numpy()  # Convert tensor to numpy array\n",
    "            adj = sp.coo_matrix(adj)  # Convert numpy array to sparse matrix\n",
    "\n",
    "        # Ensure adjacency matrix is sparse (in case it's not already)\n",
    "        if not sp.isspmatrix(adj):\n",
    "            adj = sp.coo_matrix(adj)\n",
    "\n",
    "        # Generate feature matrix (identity matrix in sparse format)\n",
    "        num_nodes = adj.shape[0]\n",
    "        features = sp.identity(num_nodes).tolil()\n",
    "\n",
    "        # Store original adjacency matrix (without diagonal entries)\n",
    "        adj_orig = adj\n",
    "        adj_orig = adj_orig - sp.dia_matrix((adj_orig.diagonal()[np.newaxis, :], [0]), shape=adj_orig.shape)\n",
    "        adj_orig.eliminate_zeros()\n",
    "\n",
    "        print(\"Original Adjacency Matrix (without diagonal):\\n\", adj_orig)\n",
    "\n",
    "        # Mask the edges (train/validation/test split)\n",
    "        train_edges, val_edges, test_edges = self.mask_test_edges(adj)\n",
    "\n",
    "        # Using the training adjacency matrix\n",
    "        adj_train = adj  # Assuming adj_train is returned or defined within mask_test_edges\n",
    "        adj_norm = preprocess_graph(adj)\n",
    "        num_nodes = adj.shape[0]\n",
    "\n",
    "        features = self.sparse_to_tuple(features.tocoo())\n",
    "        num_features = features[2][1]\n",
    "        features_nonzero = features[1].shape[0]\n",
    "\n",
    "        # Create Model\n",
    "        pos_weight = float(adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum()\n",
    "        norm = adj.shape[0] * adj.shape[0] / float((adj.shape[0] * adj.shape[0] - adj.sum()) * 2)\n",
    "\n",
    "\n",
    "        adj_label = adj_train + sp.eye(adj_train.shape[0])\n",
    "        adj_label = self.sparse_to_tuple(adj_label)\n",
    "\n",
    "\n",
    "\n",
    "        adj_norm = torch.sparse.FloatTensor(torch.LongTensor(adj_norm[0].T), \n",
    "                                    torch.FloatTensor(adj_norm[1]), \n",
    "                                    torch.Size(adj_norm[2]))\n",
    "        adj_label = torch.sparse.FloatTensor(torch.LongTensor(adj_label[0].T), \n",
    "                                    torch.FloatTensor(adj_label[1]), \n",
    "                                    torch.Size(adj_label[2]))\n",
    "        features = torch.sparse.FloatTensor(torch.LongTensor(features[0].T), \n",
    "                                    torch.FloatTensor(features[1]), \n",
    "                                    torch.Size(features[2]))\n",
    "\n",
    "        weight_mask = adj_label.to_dense().view(-1) == 1\n",
    "        weight_tensor = torch.ones(weight_mask.size(0)) \n",
    "        weight_tensor[weight_mask] = pos_weight\n",
    "\n",
    "        # init model and optimizer\n",
    "        model = getattr(vgae_model,vgae_args.model)(adj_norm)\n",
    "        optimizer = Adam(model.parameters(), lr=vgae_args.learning_rate)\n",
    "        # Initialize VGAE model with the adjacency matrix\n",
    "        adj_dense = torch.tensor(adj.toarray(), dtype=torch.float32)  # Ensure it's a tensor\n",
    "\n",
    "        model = vgae_model.VGAE(adj_dense)  # Make sure to pass the adjacency matrix during initialization\n",
    "        print(features.shape)\n",
    "        # Training loop\n",
    "        for epoch in range(vgae_args.num_epoch):\n",
    "            t = time.time()\n",
    "\n",
    "            # Pass the features to the model\n",
    "            A_pred = model(features)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = log_lik = norm * F.binary_cross_entropy(A_pred.view(-1), adj_label.to_dense().view(-1), weight=weight_tensor)\n",
    "            \n",
    "            if vgae_args.model == 'VGAE':\n",
    "                # KL divergence regularization\n",
    "                kl_divergence = 0.5 / A_pred.size(0) * (1 + 2 * model.logstd - model.mean**2 - torch.exp(model.logstd)**2).sum(1).mean()\n",
    "                loss -= kl_divergence\n",
    "\n",
    "            # Backpropagate and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Compute train accuracy\n",
    "            train_acc = self.get_acc(A_pred, adj_label)\n",
    "\n",
    "        # Get latent embeddings (mean and log standard deviation)\n",
    "        z_mean = model.mean\n",
    "        z_log_std = model.logstd\n",
    "\n",
    "        # Sample latent variables from the Gaussian distribution\n",
    "        z_sampled = z_mean + torch.randn_like(z_log_std) * torch.exp(z_log_std)\n",
    "        features = z_sampled\n",
    "        print(\"FEAT*URES\", features.shape)\n",
    "        print(features)\n",
    "        # Decode the sampled latent variables to generate a new adjacency matrix\n",
    "        new_adj_rec = torch.sigmoid(torch.matmul(z_sampled, z_sampled.t()))\n",
    "        # Generate binary adjacency matrix (threshold the probabilities)\n",
    "        threshold = 0.5  # Adjust the threshold as needed\n",
    "        new_adj_binary = (new_adj_rec > threshold).float()\n",
    "\n",
    "\n",
    "        # convert to a tensor\n",
    "        new_adj_sparse = sp.coo_matrix(new_adj_binary.detach().cpu().numpy())\n",
    "        # Ensure adj is in sparse format after edge masking\n",
    "\n",
    "        # Step 1: Convert sparse matrix to dense format\n",
    "        new_adj_dense = new_adj_sparse.toarray()  # Convert sparse COO matrix to dense array\n",
    "\n",
    "        # Step 2: Convert to PyTorch tensor\n",
    "        new_adj_tensor = torch.tensor(new_adj_dense, dtype=torch.float32, device=self.device)\n",
    "\n",
    "        # Step 3: Extract upper triangular values (excluding diagonal)\n",
    "        idx = torch.triu_indices(new_adj_tensor.size(0), new_adj_tensor.size(1), offset=1)\n",
    "        upper_tri_values = new_adj_tensor[idx[0], idx[1]]  # Extract upper triangular values\n",
    "        print(upper_tri_values.shape)\n",
    "        upper_tri_values = upper_tri_values.unsqueeze(0)  # Add a batch dimension\n",
    "        print(upper_tri_values.shape)\n",
    "\n",
    "        # Step 4: Assign to self.adj_hidden\n",
    "        if upper_tri_values.shape[1] != self.adj_hidden.shape[1]:\n",
    "            raise ValueError(f\"Size mismatch: upper_tri_values has {upper_tri_values.shape} shape, but self.adj_hidden expects {self.adj_hidden.shape}.\")\n",
    "\n",
    "        \n",
    "        return upper_tri_values, features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 4)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 2)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[-4.7029e-01, -7.0135e-01,  1.2538e+01,  1.8719e-01],\n",
      "        [-9.2681e-01, -4.3534e-01, -7.6203e+01, -4.6572e-02],\n",
      "        [-7.6534e-01, -3.8645e+00, -1.3990e+01, -5.3569e-01],\n",
      "        [-1.1745e-01, -9.8356e-01,  1.6365e+00, -2.2891e-01],\n",
      "        [ 9.1529e-01, -1.2485e+00,  1.5239e+01,  8.2841e-01]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 01 epoch: 001 train_loss= 0.70146 train_acc= 0.47500 val_loss= 0.74251 val_acc= 0.20000 time= 0.47301\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 4)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 2)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[  1.8746,  31.9863,  -1.2138,  -1.7547],\n",
      "        [  1.3510, -15.8298,   3.0989,  -2.7209],\n",
      "        [-16.9278,  -9.3726,  -2.1442,  -2.7936],\n",
      "        [  2.0225,   2.1678,   1.4251,  -1.0286],\n",
      "        [  4.6174,   8.0478,  -3.6389,  -2.2602]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 01 epoch: 002 train_loss= 0.69721 train_acc= 0.52500 val_loss= 0.72112 val_acc= 0.20000 time= 0.37693\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 4)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 2)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[-1.7017e+00,  1.0458e+01, -8.4651e+00, -5.8762e+00],\n",
      "        [-4.9133e-01,  5.5531e+00, -5.2762e-01, -1.6433e+00],\n",
      "        [-1.1325e+00, -1.4241e+01,  6.4073e+00,  2.9088e+00],\n",
      "        [-5.8743e-02,  8.6187e-01,  2.6964e-01,  1.5697e+00],\n",
      "        [-2.2547e+00,  7.3479e+01, -3.3398e+00, -1.5658e+01]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 01 epoch: 003 train_loss= 0.71590 train_acc= 0.50000 val_loss= 0.62904 val_acc= 0.80000 time= 0.37529\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 4)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 2)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[-0.5315,  0.3332,  0.4545, -0.1169],\n",
      "        [ 1.4732, -1.3119,  1.9830,  0.5371],\n",
      "        [ 1.8386, -1.4900,  1.5415,  0.8055],\n",
      "        [-0.2795, -0.8141,  2.1751, -0.3445],\n",
      "        [ 3.9294,  0.3469,  0.6309,  0.6456]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 01 epoch: 004 train_loss= 0.70807 train_acc= 0.45000 val_loss= 0.58544 val_acc= 0.80000 time= 0.47342\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 4)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 2)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[-0.7619, -0.2237, -1.1713,  0.7089],\n",
      "        [ 0.2466,  0.6703, -2.1101, -0.4473],\n",
      "        [ 0.5343,  0.3470,  1.6402, -0.3793],\n",
      "        [-0.4543,  0.2163, -0.7083, -0.2191],\n",
      "        [-1.0494, -0.8190, -0.5377,  1.6081]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 01 epoch: 005 train_loss= 0.71856 train_acc= 0.52500 val_loss= 0.68194 val_acc= 0.80000 time= 0.28912\n",
      "Optimization finished!\n",
      "Loading checkpoint!\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 4)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 2)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[-1.2973,  2.5941, -1.0207, -1.4884],\n",
      "        [-0.0080,  2.6779, -0.8253, -0.9497],\n",
      "        [-3.8199,  3.1002, -1.5138, -1.8695],\n",
      "        [-0.4833,  1.5011, -0.7325, -0.9273],\n",
      "        [-3.6488,  2.2925, -1.5804, -2.0167]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "test_loss= 0.61419 test_acc= 0.60000\n",
      "\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 4)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 1)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 0)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[ 12.8800,   4.3835,  -2.0545,   5.0312],\n",
      "        [  5.5540,   3.1436,  -1.4775,   3.4628],\n",
      "        [ -6.7625,  -0.4139,   1.4166,   1.9268],\n",
      "        [  8.0534,   1.1164,  -1.7493,   2.9258],\n",
      "        [-15.2833,   0.5639,   0.7554,   3.4938]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 02 epoch: 001 train_loss= 0.68608 train_acc= 0.57500 val_loss= 0.67756 val_acc= 0.60000 time= 0.36468\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 4)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 1)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 0)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[ 1.3101,  1.1658, -7.9837, -2.5827],\n",
      "        [ 1.5152,  0.9549, -6.7276, -2.4016],\n",
      "        [-0.8073,  8.9191, -1.4692, -2.2535],\n",
      "        [-0.2053,  3.4928, -4.7915, -2.2789],\n",
      "        [-0.8669,  7.1731,  0.4546, -2.9621]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 02 epoch: 002 train_loss= 0.69333 train_acc= 0.50000 val_loss= 0.72718 val_acc= 0.40000 time= 0.42502\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 4)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 1)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 0)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[-3.3711e+00, -1.9980e-01, -2.9004e+01, -1.1709e+01],\n",
      "        [-1.9296e-02,  1.1147e+00,  1.0810e+01,  3.1343e+00],\n",
      "        [ 4.3772e-01,  6.2212e-01,  1.0634e+00,  2.0110e-01],\n",
      "        [-2.5785e+00,  1.8410e+00,  3.7225e+00,  1.7612e+00],\n",
      "        [ 3.2803e+00,  9.6918e-01,  1.9388e+01, -2.1715e+00]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 02 epoch: 003 train_loss= 0.68362 train_acc= 0.52500 val_loss= 0.67932 val_acc= 0.60000 time= 0.32459\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 4)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 1)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 0)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[-0.2118, -2.3652,  0.0704,  5.4258],\n",
      "        [ 0.1029, -2.4151,  0.1878,  7.4148],\n",
      "        [ 1.7341, -2.7668,  0.5156, -0.1988],\n",
      "        [-1.2776, -2.1761, -0.1178,  0.4246],\n",
      "        [-0.0503, -2.4723,  0.0786, -2.9600]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 02 epoch: 004 train_loss= 0.76616 train_acc= 0.52500 val_loss= 0.70331 val_acc= 0.40000 time= 0.41830\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 4)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 1)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 0)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[-0.9628,  0.8321, -1.3605, -0.8517],\n",
      "        [ 0.9405, -0.8267, -0.1500, -0.8854],\n",
      "        [-0.4245,  0.2466,  0.0792, -1.8755],\n",
      "        [-0.8125, -0.8877, -0.9784, -0.9542],\n",
      "        [-0.4373,  0.1297,  1.2234,  0.0681]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 02 epoch: 005 train_loss= 0.72362 train_acc= 0.40000 val_loss= 0.71618 val_acc= 0.40000 time= 0.42459\n",
      "Optimization finished!\n",
      "Loading checkpoint!\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 4)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 1)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 0)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[ 2.4780,  3.8403,  0.7484, -0.2382],\n",
      "        [-1.1886,  0.2720,  0.4792,  0.3941],\n",
      "        [ 2.2927, -0.7811,  1.5785,  2.1083],\n",
      "        [ 2.4808, -1.7266,  1.5986,  0.7376],\n",
      "        [-1.8884, -4.8913,  1.6296,  4.6329]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "test_loss= 0.69043 test_acc= 0.60000\n",
      "\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 2)\t1\n",
      "  (0, 4)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 3)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 0)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[ -1.1426,   1.2104,  -5.7960,   0.7843],\n",
      "        [  1.6807,  -0.0837,  -0.0290,   0.2731],\n",
      "        [ -1.0927,  -0.5144,  -0.2845,   0.7030],\n",
      "        [  1.6177,  -1.1286,   5.6464,   3.9873],\n",
      "        [ -0.3186,   0.7678, -10.4707,   0.5120]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 03 epoch: 001 train_loss= 0.66913 train_acc= 0.60000 val_loss= 0.68620 val_acc= 0.40000 time= 0.32709\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 2)\t1\n",
      "  (0, 4)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 3)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 0)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[ 3.5470, -0.4817, -2.0554,  1.8365],\n",
      "        [ 0.2135,  0.1981,  0.5334,  0.1557],\n",
      "        [ 0.7697,  0.1821, -0.8977, -0.1241],\n",
      "        [-0.5028,  2.2272, -3.9533,  2.1080],\n",
      "        [ 0.6140,  1.2262, -0.2585,  0.2051]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 03 epoch: 002 train_loss= 0.72528 train_acc= 0.42500 val_loss= 0.71887 val_acc= 0.60000 time= 0.37417\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 2)\t1\n",
      "  (0, 4)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 3)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 0)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[-2.5799,  0.5564, -0.9992, -1.8765],\n",
      "        [-0.1201, -0.9961,  0.5481, -1.9606],\n",
      "        [-5.6832,  0.7989, -2.4607, -2.1180],\n",
      "        [ 6.9414,  0.0612,  1.5780,  0.8334],\n",
      "        [-1.2850,  1.0883, -1.1411,  0.1752]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 03 epoch: 003 train_loss= 0.70554 train_acc= 0.45000 val_loss= 0.79199 val_acc= 0.20000 time= 0.40862\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 2)\t1\n",
      "  (0, 4)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 3)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 0)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[ 1.4603, -0.0917, -1.3744,  0.9949],\n",
      "        [ 0.1216, -0.4813,  0.7698,  1.2519],\n",
      "        [ 1.2424, -4.4842, -0.9322,  4.7932],\n",
      "        [-0.7306,  0.2699,  0.9000, -0.2848],\n",
      "        [ 1.6680,  2.1359,  1.3674, -0.6143]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 03 epoch: 004 train_loss= 0.71002 train_acc= 0.47500 val_loss= 0.62923 val_acc= 0.80000 time= 0.44481\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 2)\t1\n",
      "  (0, 4)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 3)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 0)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[-0.7530,  0.5914, -0.0408,  1.4654],\n",
      "        [ 0.2402, -0.6066, -1.2918,  1.1984],\n",
      "        [-1.6083, -0.6563,  1.7593,  0.3150],\n",
      "        [-1.1035, -0.8120, -0.3028,  0.9327],\n",
      "        [-0.0713,  0.0427, -1.4337, -1.2964]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 03 epoch: 005 train_loss= 0.68408 train_acc= 0.65000 val_loss= 0.72619 val_acc= 0.40000 time= 0.29576\n",
      "Optimization finished!\n",
      "Loading checkpoint!\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 2)\t1\n",
      "  (0, 4)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 3)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 0)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[ 1.3153, -0.2712,  1.4931,  0.7607],\n",
      "        [ 0.2150,  2.2691,  0.4800, -0.0808],\n",
      "        [ 1.0287, -0.8197, -1.0347, -0.3130],\n",
      "        [ 1.9183,  0.3514,  1.8071,  0.5888],\n",
      "        [ 0.6587, -1.1728, -0.1442,  1.5180]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "test_loss= 0.70025 test_acc= 0.40000\n",
      "\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 1)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 4)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 2)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[-3.8183, -0.7851,  0.6376, -0.1885],\n",
      "        [ 1.5480, -1.4701, -0.1736,  0.7605],\n",
      "        [ 0.6031, -1.2905, -1.4050,  0.5684],\n",
      "        [ 3.0467, -1.8213,  0.2826,  1.4165],\n",
      "        [10.6880, -1.7767,  0.9314,  0.3601]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 04 epoch: 001 train_loss= 0.68695 train_acc= 0.52500 val_loss= 0.82123 val_acc= 0.20000 time= 0.32829\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 1)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 4)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 2)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[  1.5877,   2.1264,  -1.1123,  -7.1914],\n",
      "        [-10.7566,   6.2579,   1.9024,   1.6768],\n",
      "        [  0.9441,   1.2278,  -0.0512,  -3.7245],\n",
      "        [  0.0993,  -6.6963,   2.2031,  -2.2620],\n",
      "        [  1.0308,  -1.8582,  -1.1417,  -2.2036]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 04 epoch: 002 train_loss= 0.70589 train_acc= 0.47500 val_loss= 0.95946 val_acc= 0.20000 time= 0.34806\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 1)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 4)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 2)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[ 2.6514, -0.3214,  0.7522, -2.0170],\n",
      "        [-0.2235,  2.2836,  2.6449, -2.0951],\n",
      "        [-0.9728,  1.2992, -0.2608, -1.5100],\n",
      "        [-0.0349,  0.2385,  1.0441, -6.2993],\n",
      "        [ 0.5427,  0.8711,  1.4850, -0.2896]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 04 epoch: 003 train_loss= 0.78039 train_acc= 0.50000 val_loss= 0.66646 val_acc= 0.80000 time= 0.42509\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 1)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 4)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 2)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[ 0.7920, -0.3621, -0.3053,  0.3648],\n",
      "        [-0.8909, -0.4041, -1.7240, -1.1584],\n",
      "        [-0.9969,  0.3246, -0.4691, -0.9563],\n",
      "        [-1.1263, -0.1527, -0.3524, -0.3920],\n",
      "        [ 0.4706, -2.4163, -0.4902, -0.1077]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 04 epoch: 004 train_loss= 0.73700 train_acc= 0.50000 val_loss= 0.68246 val_acc= 0.80000 time= 0.41486\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 1)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 4)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 2)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[ 0.8708,  0.6897, -1.4250, -0.5854],\n",
      "        [-1.3177,  0.0544,  1.7271, -0.5228],\n",
      "        [-1.9020, -1.0583, -0.3351, -0.1461],\n",
      "        [-0.3706,  0.6041, -0.4412,  1.2715],\n",
      "        [ 1.1556,  1.0693,  0.3337,  0.1594]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 04 epoch: 005 train_loss= 0.68938 train_acc= 0.47500 val_loss= 0.69956 val_acc= 0.20000 time= 0.42685\n",
      "Optimization finished!\n",
      "Loading checkpoint!\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 1)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 4)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 2)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[ 3.3866, -1.6914, -1.1353,  0.6456],\n",
      "        [ 2.4722, -2.5068,  1.0465, -1.2264],\n",
      "        [ 0.8240, -0.0860, -1.1619,  0.5295],\n",
      "        [ 0.6724,  2.7956,  0.1373,  1.4165],\n",
      "        [ 4.6716,  0.4485,  0.5470,  2.2735]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "test_loss= 0.70331 test_acc= 0.40000\n",
      "\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 4)\t1\n",
      "  (1, 0)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 0)\t1\n",
      "  (4, 2)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[ 1.8322, -3.1927, -1.7503, -1.8300],\n",
      "        [-1.4807,  0.3042, -0.9044, -2.3706],\n",
      "        [-2.0783,  0.2216, -1.2288, -2.2073],\n",
      "        [ 0.7216, -1.9607, -1.3321, -2.1563],\n",
      "        [ 1.0571, -1.0015, -1.2415, -1.3448]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 05 epoch: 001 train_loss= 0.70774 train_acc= 0.45000 val_loss= 0.68269 val_acc= 1.00000 time= 0.39386\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 4)\t1\n",
      "  (1, 0)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 0)\t1\n",
      "  (4, 2)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[ 0.0540, -1.7277, -2.4162,  1.4936],\n",
      "        [ 0.3936,  0.1492, -1.6599, -0.7829],\n",
      "        [-1.4113,  0.9000, -0.7289,  0.3756],\n",
      "        [-0.2610, -0.3803, -2.6455,  3.2843],\n",
      "        [-3.6867,  0.0468, -2.1570, -0.0062]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 05 epoch: 002 train_loss= 0.80289 train_acc= 0.45000 val_loss= 0.54775 val_acc= 1.00000 time= 0.32910\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 4)\t1\n",
      "  (1, 0)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 0)\t1\n",
      "  (4, 2)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[-2.5419,  0.3052,  2.9092,  1.3672],\n",
      "        [ 1.1052, -0.1255, -0.4769,  1.5237],\n",
      "        [ 0.4825, -0.3892,  3.2410,  1.4752],\n",
      "        [-0.3158, -0.8085,  1.5622,  0.7411],\n",
      "        [ 0.7463, -0.8589,  0.8571, -0.0885]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 05 epoch: 003 train_loss= 0.67327 train_acc= 0.47500 val_loss= 0.65015 val_acc= 1.00000 time= 0.32869\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 4)\t1\n",
      "  (1, 0)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 0)\t1\n",
      "  (4, 2)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[-0.1674, -0.6153, -1.8904,  1.5547],\n",
      "        [ 0.1934, -1.0324,  0.9065, -0.8379],\n",
      "        [ 1.6304, -0.9322,  0.0807,  0.6015],\n",
      "        [ 0.5401, -0.7506, -1.6041,  1.8891],\n",
      "        [-1.9792, -0.4278, -0.7980,  1.4213]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 05 epoch: 004 train_loss= 0.71664 train_acc= 0.47500 val_loss= 0.68840 val_acc= 1.00000 time= 0.47628\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 4)\t1\n",
      "  (1, 0)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 0)\t1\n",
      "  (4, 2)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[-0.0207, -0.4453, -0.2064,  0.3716],\n",
      "        [ 0.4686,  0.9201, -0.7907, -0.6950],\n",
      "        [-0.3398,  5.5015, -0.0811,  0.0368],\n",
      "        [-0.7787, -2.9852, -0.6684,  2.2687],\n",
      "        [-0.8704,  3.9550, -0.9016, -1.1962]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 05 epoch: 005 train_loss= 0.68575 train_acc= 0.50000 val_loss= 0.57844 val_acc= 1.00000 time= 0.31075\n",
      "Optimization finished!\n",
      "Loading checkpoint!\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 4)\t1\n",
      "  (1, 0)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 0)\t1\n",
      "  (4, 2)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[-1.3727, -2.3253,  1.0305, -0.3422],\n",
      "        [ 0.3564, -0.7662,  0.6433,  1.4667],\n",
      "        [-0.5964, -1.8739, -2.6215, -4.6902],\n",
      "        [-0.8194, -1.8579,  0.5085, -1.1148],\n",
      "        [-0.5534,  2.6338, -1.0010,  5.7260]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "test_loss= 0.73550 test_acc= 0.40000\n",
      "\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 1)\t1\n",
      "  (1, 0)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 2)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[-1.7925, -1.0983,  2.6059,  1.1329],\n",
      "        [ 0.9330, -1.2142,  0.2762, -2.1363],\n",
      "        [-0.0261,  0.9282,  0.5001,  1.4555],\n",
      "        [ 2.0353, -0.0799,  0.9925,  1.5877],\n",
      "        [-1.0434,  0.7569, -3.0914, -2.5052]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 06 epoch: 001 train_loss= 0.70369 train_acc= 0.47500 val_loss= 0.61401 val_acc= 0.80000 time= 0.36160\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 1)\t1\n",
      "  (1, 0)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 2)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[-0.6839,  1.6476,  0.1514, -0.9105],\n",
      "        [ 0.4211,  1.5891,  0.1206,  0.0634],\n",
      "        [-1.1953,  0.8794, -0.2805, -0.7439],\n",
      "        [-1.1488,  0.6584, -0.5053, -2.4421],\n",
      "        [ 0.0984,  1.5814, -1.1047, -0.8935]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 06 epoch: 002 train_loss= 0.69688 train_acc= 0.50000 val_loss= 0.70038 val_acc= 0.20000 time= 0.34770\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 1)\t1\n",
      "  (1, 0)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 2)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[ 1.1325, -0.9248, -0.3188,  0.0399],\n",
      "        [ 0.6412, -0.3830, -0.1307, -1.0342],\n",
      "        [ 1.2957, -2.7207, -2.2935,  1.1937],\n",
      "        [ 0.7916, -0.7663, -0.9404,  0.6270],\n",
      "        [ 2.2820, -0.5666,  1.2744,  0.0928]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 06 epoch: 003 train_loss= 0.68718 train_acc= 0.47500 val_loss= 0.62249 val_acc= 0.80000 time= 0.42822\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 1)\t1\n",
      "  (1, 0)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 2)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[ 0.1096, -1.4573, -0.4829, -0.5410],\n",
      "        [ 0.1161, -1.1639, -1.4265, -0.1620],\n",
      "        [ 0.9535, -0.8451,  2.3768,  3.6086],\n",
      "        [ 0.2742, -1.8644,  0.3351,  2.2914],\n",
      "        [ 0.8027,  3.0892,  0.5946, -1.2849]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 06 epoch: 004 train_loss= 0.73278 train_acc= 0.42500 val_loss= 0.66511 val_acc= 0.80000 time= 0.36615\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 1)\t1\n",
      "  (1, 0)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 2)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[ 0.7470, -0.2487, -2.4611,  0.4558],\n",
      "        [-0.4480,  0.4981, -0.0644,  0.5971],\n",
      "        [-0.0830,  0.4462, -1.9859, -0.8911],\n",
      "        [-1.1152,  1.5213,  2.3027,  1.9093],\n",
      "        [-0.0457, -1.5103,  5.5432, -0.1934]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 06 epoch: 005 train_loss= 0.67582 train_acc= 0.47500 val_loss= 0.64821 val_acc= 0.80000 time= 0.40231\n",
      "Optimization finished!\n",
      "Loading checkpoint!\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 1)\t1\n",
      "  (1, 0)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 2)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[-1.5590,  2.1082,  1.1627,  1.3639],\n",
      "        [ 2.4387, -0.2737, -0.2086, -0.3773],\n",
      "        [-1.0989,  0.4118, -1.8769,  0.3111],\n",
      "        [-0.5734,  1.1554, -1.3003,  0.3390],\n",
      "        [-0.5881,  1.5345,  6.2770,  1.5212]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "test_loss= 0.69967 test_acc= 0.40000\n",
      "\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (2, 3)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 0)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[-0.2581, -1.5434, -1.0783, -1.1915],\n",
      "        [ 1.6776,  0.7724,  0.4361,  0.9379],\n",
      "        [-0.5359,  1.3909,  0.6447, -0.9975],\n",
      "        [ 0.8974,  3.4478, -0.0482,  0.1822],\n",
      "        [ 2.0155,  2.3643,  0.8130, -1.3265]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 07 epoch: 001 train_loss= 0.68289 train_acc= 0.50000 val_loss= 0.78401 val_acc= 0.40000 time= 0.38847\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (2, 3)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 0)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[-0.9907, -5.4906, -1.7868,  2.2150],\n",
      "        [-0.9839,  1.1738, -0.6587,  1.1637],\n",
      "        [ 1.2054,  1.7732, -1.2100,  0.0066],\n",
      "        [-5.5616,  0.1680, -1.9725,  0.3344],\n",
      "        [ 1.6280,  0.7899, -1.6749, -1.1856]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 07 epoch: 002 train_loss= 0.70107 train_acc= 0.52500 val_loss= 0.68720 val_acc= 0.60000 time= 0.39346\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (2, 3)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 0)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[-2.2481,  2.3474,  0.6256, -0.0579],\n",
      "        [-0.7193,  1.0605, -0.7765,  0.1795],\n",
      "        [ 0.2494, -2.3029,  0.2661,  0.0079],\n",
      "        [-0.1861,  0.8118, -0.5412,  0.0527],\n",
      "        [ 0.0513,  2.7042, -0.5722, -0.0470]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 07 epoch: 003 train_loss= 0.69537 train_acc= 0.57500 val_loss= 0.68665 val_acc= 0.60000 time= 0.35542\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (2, 3)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 0)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[-0.8313,  1.7798, -7.0126,  1.9137],\n",
      "        [-0.0113, -0.5711,  0.0120, -0.9815],\n",
      "        [-0.6803,  0.3317,  0.7224,  1.0043],\n",
      "        [-0.2317, -0.5994,  5.5529,  2.0023],\n",
      "        [-0.4090,  1.1855,  1.4639,  0.5306]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 07 epoch: 004 train_loss= 0.69111 train_acc= 0.45000 val_loss= 0.68493 val_acc= 0.60000 time= 0.36508\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (2, 3)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 0)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[-0.6605, -1.2054,  0.3578, -3.0364],\n",
      "        [-1.0319, -0.4015,  0.4737,  1.6788],\n",
      "        [-0.8549, -1.4889,  1.7242, -2.3071],\n",
      "        [-0.7528,  0.6806,  1.3635,  1.8240],\n",
      "        [-0.6544, -0.9894, -0.6944, -3.5401]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 07 epoch: 005 train_loss= 0.72489 train_acc= 0.45000 val_loss= 0.68806 val_acc= 0.60000 time= 0.42055\n",
      "Optimization finished!\n",
      "Loading checkpoint!\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (2, 3)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 0)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[ 4.0871e-02,  3.9413e+00,  4.1240e+00, -3.9787e-01],\n",
      "        [-1.2833e+00, -2.7516e+00,  2.1904e+00, -4.8859e-03],\n",
      "        [-5.2179e-01, -9.1003e-01, -1.9771e+00,  1.1793e+00],\n",
      "        [ 1.3510e+00,  3.2339e+01,  4.2804e+00,  1.3601e-01],\n",
      "        [-4.0658e-02, -1.0461e+00, -2.6041e-01,  1.2759e+00]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "test_loss= 0.71138 test_acc= 0.40000\n",
      "\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 1)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 3)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 1)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 2)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[-0.0643,  1.9621, -2.3731, -0.2911],\n",
      "        [-0.0919, -0.8582,  0.3043,  0.9181],\n",
      "        [-3.3512,  1.2129,  0.3851,  1.2593],\n",
      "        [-1.8103,  1.7480,  0.7313, -2.1889],\n",
      "        [-0.1692, -1.0766,  0.8562, -0.0859]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 08 epoch: 001 train_loss= 0.69638 train_acc= 0.52500 val_loss= 0.62686 val_acc= 0.80000 time= 0.39770\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 1)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 3)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 1)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 2)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[ 1.2128,  0.6899, -2.7235, -1.5388],\n",
      "        [ 2.3413,  0.5694, -2.6858, -0.0601],\n",
      "        [ 1.2234, -1.1183, -0.2783, -1.0175],\n",
      "        [ 7.7922, -3.4411, -1.6959,  2.0540],\n",
      "        [ 1.4763, -0.6190, -1.1743, -0.0119]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 08 epoch: 002 train_loss= 0.68056 train_acc= 0.47500 val_loss= 0.64311 val_acc= 0.80000 time= 0.41594\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 1)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 3)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 1)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 2)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[ 0.6105, -0.1042,  1.4079, -0.8654],\n",
      "        [-0.0899,  0.6808,  0.3741,  1.2503],\n",
      "        [ 0.8423, -1.1250,  0.8837,  0.9272],\n",
      "        [-0.3335,  0.5684, -0.1535,  1.0586],\n",
      "        [ 0.6640, -0.8096, -1.2761, -0.0093]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 08 epoch: 003 train_loss= 0.72984 train_acc= 0.47500 val_loss= 0.73274 val_acc= 0.20000 time= 0.42859\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 1)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 3)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 1)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 2)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[ 0.1998,  0.0570,  0.6502, -0.1643],\n",
      "        [ 1.2933,  0.3957, -0.5714,  1.8789],\n",
      "        [ 2.2268, -1.5406,  0.0173,  0.7539],\n",
      "        [-0.3291, -2.4593, -0.1171,  0.7420],\n",
      "        [ 0.0029,  0.4163, -1.2294,  1.4653]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 08 epoch: 004 train_loss= 0.72563 train_acc= 0.55000 val_loss= 0.65244 val_acc= 0.80000 time= 0.29715\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 1)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 3)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 1)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 2)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[-7.2988e-01,  1.1966e+00,  5.9951e-03,  1.2862e+00],\n",
      "        [-6.8662e+00,  3.1521e-01,  8.1965e-01, -1.0687e+00],\n",
      "        [ 1.7224e+00,  5.0761e-01, -2.2829e+00, -1.7375e+00],\n",
      "        [ 9.8851e+00,  9.8766e-01,  1.4355e+01, -3.4994e-01],\n",
      "        [ 2.4117e+00,  1.2249e+00,  1.8482e-01, -8.6172e-01]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 08 epoch: 005 train_loss= 0.71246 train_acc= 0.47500 val_loss= 0.66968 val_acc= 0.80000 time= 0.41808\n",
      "Optimization finished!\n",
      "Loading checkpoint!\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 1)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 3)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 1)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 2)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[-1.8198, -0.5802,  1.0185, -0.2382],\n",
      "        [-0.5250,  0.6873,  0.4840, -0.6404],\n",
      "        [-0.4448, -1.9078, -0.3547,  0.8004],\n",
      "        [-0.8966, -0.1356,  0.2679,  1.9324],\n",
      "        [-1.1810, -5.7997,  2.7528, -1.3833]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "test_loss= 0.70767 test_acc= 0.40000\n",
      "\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 1)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 4)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 1)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[ 0.5649, -1.6709,  1.3639, -0.3319],\n",
      "        [-1.0445,  1.0726, -0.6932, -1.1843],\n",
      "        [-0.9284, -1.2373, -0.5742,  0.7205],\n",
      "        [-0.8771,  1.0087,  1.5986, -1.0652],\n",
      "        [ 0.6335, -1.7460,  0.6620,  4.3971]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 09 epoch: 001 train_loss= 0.74410 train_acc= 0.47500 val_loss= 0.69689 val_acc= 0.40000 time= 0.45908\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 1)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 4)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 1)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[-1.4335, -0.5956,  1.8220, -0.0305],\n",
      "        [-0.8876,  0.7583, -2.7338,  1.6028],\n",
      "        [ 1.2613, -0.4700, -0.8847,  0.1134],\n",
      "        [ 2.6122, -0.3784,  0.8355,  1.5503],\n",
      "        [ 2.5544, -1.1604, -0.4349,  0.4873]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 09 epoch: 002 train_loss= 0.70943 train_acc= 0.50000 val_loss= 0.67670 val_acc= 0.60000 time= 0.36687\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 1)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 4)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 1)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[-1.3736, -0.4927, -1.7316,  0.3401],\n",
      "        [-1.2401, -1.5184, -1.2867,  0.8948],\n",
      "        [-0.5224, -1.1334,  0.0537, -0.1357],\n",
      "        [ 1.7582, -1.7407, -1.3593,  0.5034],\n",
      "        [-0.6910,  1.4849, -0.3449,  3.4834]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 09 epoch: 003 train_loss= 0.72184 train_acc= 0.47500 val_loss= 0.67331 val_acc= 0.60000 time= 0.44598\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 1)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 4)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 1)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[ 0.4839,  2.2201,  3.2802, -0.7832],\n",
      "        [ 2.1044,  4.7748, -2.9538, -1.5695],\n",
      "        [-1.3791,  1.8141,  1.1333,  1.1324],\n",
      "        [ 1.2373,  2.6949, -1.0314, -0.8714],\n",
      "        [-0.3411,  0.3398, -1.4745, -0.7695]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 09 epoch: 004 train_loss= 0.73382 train_acc= 0.40000 val_loss= 0.67704 val_acc= 0.60000 time= 0.34254\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 1)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 4)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 1)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[ 0.1087,  2.2273,  5.7954,  0.6645],\n",
      "        [ 1.8992,  2.9944,  3.3784,  0.5371],\n",
      "        [ 0.4554, -0.2733, -0.3779,  0.2872],\n",
      "        [ 2.1923,  3.3164,  2.6325,  0.8205],\n",
      "        [-0.0289,  4.0725, -4.4153,  1.7097]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 09 epoch: 005 train_loss= 0.75870 train_acc= 0.47500 val_loss= 0.68577 val_acc= 0.60000 time= 0.44021\n",
      "Optimization finished!\n",
      "Loading checkpoint!\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 1)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 4)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 1)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[-2.7304,  2.9367,  2.1322,  0.1179],\n",
      "        [ 0.4974,  0.8323,  0.1455,  0.0489],\n",
      "        [ 0.9082, -0.1761,  0.1225, -0.1870],\n",
      "        [-0.5966, -2.5752,  0.2720, -0.1269],\n",
      "        [-2.8261, -6.9069,  2.3019,  0.2342]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "test_loss= 0.68473 test_acc= 0.80000\n",
      "\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 2)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 4)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 3)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[ -0.1539,   0.4884,   2.0057,  -4.8508],\n",
      "        [ -0.2872,   1.5867,   2.9066,  -1.4528],\n",
      "        [ -3.2034,  -0.3677,   4.2346, -40.9210],\n",
      "        [ -1.5966,   0.9003,   3.2590,  -5.7112],\n",
      "        [ -2.0475,   0.2350,  -0.3450,  -2.6906]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 10 epoch: 001 train_loss= 0.72673 train_acc= 0.52500 val_loss= 0.69443 val_acc= 0.40000 time= 0.38018\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 2)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 4)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 3)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[ -8.2947,   1.3947,  -0.5738, -13.0740],\n",
      "        [ 20.0872,   0.5037,  -1.3645, -93.7289],\n",
      "        [ -1.1728,   0.6128,   0.0978,  -0.2110],\n",
      "        [  1.4600,   0.4009,  -1.3021, -30.1262],\n",
      "        [ -1.2719,  -0.2760,  -0.3406,   0.2578]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 10 epoch: 002 train_loss= 0.76524 train_acc= 0.55000 val_loss= 0.69671 val_acc= 0.40000 time= 0.37569\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 2)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 4)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 3)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[-4.0610,  1.2873,  0.5703,  1.8086],\n",
      "        [ 0.0423,  7.5952,  2.2160,  1.2709],\n",
      "        [ 1.0744, -1.6615,  2.0512, -2.3723],\n",
      "        [-6.3199,  1.6071,  2.0121,  1.0993],\n",
      "        [ 0.6500,  1.9546,  1.5549,  1.4904]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 10 epoch: 003 train_loss= 0.67630 train_acc= 0.55000 val_loss= 0.72050 val_acc= 0.40000 time= 0.35846\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 2)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 4)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 3)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[-0.5616,  0.1793, -0.2499,  0.0425],\n",
      "        [-1.3500,  1.1035, -0.4121,  0.7498],\n",
      "        [ 0.9771, -3.6882,  1.0133, -0.0454],\n",
      "        [-1.5340,  2.3102, -0.3086,  1.4210],\n",
      "        [ 0.2677, -2.1131, -1.0405, -0.2823]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 10 epoch: 004 train_loss= 0.70619 train_acc= 0.55000 val_loss= 0.67979 val_acc= 0.60000 time= 0.36937\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 2)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 4)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 3)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[ 0.5166,  2.6040,  2.3064, -1.7058],\n",
      "        [ 0.7248,  1.9705,  1.6579, -1.5431],\n",
      "        [ 0.5071, -0.1027,  0.0560,  0.9383],\n",
      "        [ 0.6332, 14.1012,  1.2843,  0.3738],\n",
      "        [ 0.0551,  0.3416,  1.0386, -2.1219]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "Cross-val iter: 10 epoch: 005 train_loss= 0.66934 train_acc= 0.55000 val_loss= 0.67310 val_acc= 0.60000 time= 0.42993\n",
      "Optimization finished!\n",
      "Loading checkpoint!\n",
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 2)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 4)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 3)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n",
      "torch.Size([5, 5])\n",
      "FEAT*URES torch.Size([5, 4])\n",
      "tensor([[ 1.4207,  0.0111,  1.9653,  1.9869],\n",
      "        [-0.0692,  0.1020,  1.0499,  1.0021],\n",
      "        [ 0.0800,  0.8768,  0.7373, -0.4458],\n",
      "        [ 0.0332, -0.3271,  0.1145,  0.9645],\n",
      "        [ 0.0261,  0.5816,  1.2556,  1.1361]], grad_fn=<AddBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "FEATURE SHAPE torch.Size([120, 1])\n",
      "test_loss= 0.72420 test_acc= 0.40000\n",
      "\n",
      "avg_test_acc= 0.48000\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(y):\n",
    "    it += 1\n",
    "    \n",
    "    idx = np.random.permutation(train_index)\n",
    "    train_index = idx[:int(idx.size*0.9)].tolist()\n",
    "    val_index = idx[int(idx.size*0.9):].tolist()\n",
    "\n",
    "    n_train = len(train_index)\n",
    "    n_val = len(val_index)\n",
    "    n_test = len(test_index)\n",
    "\n",
    "    adj_train = [adj_lst[i] for i in train_index]\n",
    "    features_train = [features_lst[i] for i in train_index]\n",
    "    y_train = [y[i] for i in train_index]\n",
    "\n",
    "    adj_val = [adj_lst[i] for i in val_index]\n",
    "    features_val = [features_lst[i] for i in val_index]\n",
    "    y_val = [y[i] for i in val_index]\n",
    "\n",
    "    adj_test = [adj_lst[i] for i in test_index]\n",
    "    features_test = [features_lst[i] for i in test_index]\n",
    "    y_test = [y[i] for i in test_index]\n",
    "\n",
    "    adj_train, features_train, graph_indicator_train, y_train = generate_batches(adj_train, features_train, y_train, args.batch_size, device)\n",
    "    adj_val, features_val, graph_indicator_val, y_val = generate_batches(adj_val, features_val, y_val, args.batch_size, device)\n",
    "    adj_test, features_test, graph_indicator_test, y_test = generate_batches(adj_test, features_test, y_test, args.batch_size, device)\n",
    "\n",
    "    n_train_batches = ceil(n_train/args.batch_size)\n",
    "    n_val_batches = ceil(n_val/args.batch_size)\n",
    "    n_test_batches = ceil(n_test/args.batch_size)\n",
    "    \n",
    "    model = RW_NN(features_dim, args.max_step, args.hidden_graphs, args.size_hidden_graphs, args.hidden_dim, args.penultimate_dim, args.normalize, n_classes, args.dropout, device).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "\n",
    "    def train(epoch, adj, features, graph_indicator, y):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(adj, features, graph_indicator)\n",
    "        loss_train = F.cross_entropy(output, y)\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        return output, loss_train\n",
    "\n",
    "    def test(adj, features, graph_indicator, y):\n",
    "        output = model(adj, features, graph_indicator)\n",
    "        loss_test = F.cross_entropy(output, y)\n",
    "        return output, loss_test\n",
    "\n",
    "    best_acc = 0\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        start = time.time()\n",
    "        model.train()\n",
    "        train_loss = AverageMeter()\n",
    "        train_acc = AverageMeter()\n",
    "\n",
    "        # Train for one epoch\n",
    "        for i in range(n_train_batches):\n",
    "            output, loss = train(epoch, adj_train[i], features_train[i], graph_indicator_train[i], y_train[i])\n",
    "            train_loss.update(loss.item(), output.size(0))\n",
    "            train_acc.update(accuracy(output.data, y_train[i].data), output.size(0))\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        model.eval()\n",
    "        val_loss = AverageMeter()\n",
    "        val_acc = AverageMeter()\n",
    "\n",
    "        for i in range(n_val_batches):\n",
    "            output, loss = test(adj_val[i], features_val[i], graph_indicator_val[i], y_val[i])\n",
    "            val_loss.update(loss.item(), output.size(0))\n",
    "            val_acc.update(accuracy(output.data, y_val[i].data), output.size(0))\n",
    "\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Print results\n",
    "        print(\"Cross-val iter:\", '%02d' % it, \"epoch:\", '%03d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(train_loss.avg),\n",
    "            \"train_acc=\", \"{:.5f}\".format(train_acc.avg), \"val_loss=\", \"{:.5f}\".format(val_loss.avg),\n",
    "            \"val_acc=\", \"{:.5f}\".format(val_acc.avg), \"time=\", \"{:.5f}\".format(time.time() - start))\n",
    "        \n",
    "        # Remember best accuracy and save checkpoint\n",
    "        is_best = val_acc.avg >= best_acc\n",
    "        best_acc = max(val_acc.avg, best_acc)\n",
    "        if is_best:\n",
    "            early_stopping_counter = 0\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'optimizer' : optimizer.state_dict(),\n",
    "            }, 'model_best.pth.tar')\n",
    "\n",
    "    print(\"Optimization finished!\")\n",
    "\n",
    "    # Testing\n",
    "    test_loss = AverageMeter()\n",
    "    test_acc = AverageMeter()\n",
    "    print(\"Loading checkpoint!\")\n",
    "    checkpoint = torch.load('model_best.pth.tar')\n",
    "    epoch = checkpoint['epoch']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    \n",
    "    for i in range(n_test_batches):\n",
    "        output, loss = test(adj_test[i], features_test[i], graph_indicator_test[i], y_test[i])\n",
    "        test_loss.update(loss.item(), output.size(0))\n",
    "        test_acc.update(accuracy(output.data, y_test[i].data), output.size(0))\n",
    "    accs.append(test_acc.avg.cpu().numpy())\n",
    "\n",
    "    # Print results\n",
    "    print(\"test_loss=\", \"{:.5f}\".format(test_loss.avg), \"test_acc=\", \"{:.5f}\".format(test_acc.avg))\n",
    "    print()\n",
    "    \n",
    "print(\"avg_test_acc=\", \"{:.5f}\".format(np.mean(accs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Graph 0:\n",
      "  Node 0: [2]\n",
      "  Node 1: [2, 4]\n",
      "  Node 2: [0, 1, 3]\n",
      "  Node 3: [2, 4]\n",
      "  Node 4: [1, 3]\n",
      "Hidden Graph 1:\n",
      "  Node 0: [3, 4]\n",
      "  Node 1: [4]\n",
      "  Node 2: [3]\n",
      "  Node 3: [0, 2, 4]\n",
      "  Node 4: [0, 1, 3]\n",
      "Hidden Graph 2:\n",
      "  Node 0: [1, 3]\n",
      "  Node 1: [0]\n",
      "  Node 2: [4]\n",
      "  Node 3: [0, 4]\n",
      "  Node 4: [2, 3]\n",
      "Hidden Graph 3:\n",
      "  Node 0: [1]\n",
      "  Node 1: [0, 3]\n",
      "  Node 2: []\n",
      "  Node 3: [1, 4]\n",
      "  Node 4: [3]\n",
      "Hidden Graph 4:\n",
      "  Node 0: [3]\n",
      "  Node 1: [4]\n",
      "  Node 2: []\n",
      "  Node 3: [0]\n",
      "  Node 4: [1]\n",
      "Hidden Graph 5:\n",
      "  Node 0: [4]\n",
      "  Node 1: [2]\n",
      "  Node 2: [1, 3]\n",
      "  Node 3: [2]\n",
      "  Node 4: [0]\n",
      "Hidden Graph 6:\n",
      "  Node 0: []\n",
      "  Node 1: [2, 4]\n",
      "  Node 2: [1]\n",
      "  Node 3: []\n",
      "  Node 4: [1]\n",
      "Hidden Graph 7:\n",
      "  Node 0: [2, 3]\n",
      "  Node 1: [3]\n",
      "  Node 2: [0]\n",
      "  Node 3: [0, 1, 4]\n",
      "  Node 4: [3]\n",
      "Hidden Graph 8:\n",
      "  Node 0: []\n",
      "  Node 1: []\n",
      "  Node 2: []\n",
      "  Node 3: [4]\n",
      "  Node 4: [3]\n",
      "Hidden Graph 9:\n",
      "  Node 0: [2, 3]\n",
      "  Node 1: [2]\n",
      "  Node 2: [0, 1, 3]\n",
      "  Node 3: [0, 2]\n",
      "  Node 4: []\n",
      "Hidden Graph 10:\n",
      "  Node 0: [1, 2]\n",
      "  Node 1: [0, 2, 3]\n",
      "  Node 2: [0, 1, 3, 4]\n",
      "  Node 3: [1, 2, 4]\n",
      "  Node 4: [2, 3]\n",
      "Hidden Graph 11:\n",
      "  Node 0: [1, 2, 3]\n",
      "  Node 1: [0, 2, 3]\n",
      "  Node 2: [0, 1, 4]\n",
      "  Node 3: [0, 1, 4]\n",
      "  Node 4: [2, 3]\n",
      "Hidden Graph 12:\n",
      "  Node 0: [1, 3]\n",
      "  Node 1: [0, 3]\n",
      "  Node 2: [4]\n",
      "  Node 3: [0, 1]\n",
      "  Node 4: [2]\n",
      "Hidden Graph 13:\n",
      "  Node 0: [2, 3]\n",
      "  Node 1: [4]\n",
      "  Node 2: [0, 3]\n",
      "  Node 3: [0, 2]\n",
      "  Node 4: [1]\n",
      "Hidden Graph 14:\n",
      "  Node 0: [2, 3]\n",
      "  Node 1: [3]\n",
      "  Node 2: [0, 3, 4]\n",
      "  Node 3: [0, 1, 2]\n",
      "  Node 4: [2]\n",
      "Hidden Graph 15:\n",
      "  Node 0: [1, 3, 4]\n",
      "  Node 1: [0, 4]\n",
      "  Node 2: []\n",
      "  Node 3: [0]\n",
      "  Node 4: [0, 1]\n"
     ]
    }
   ],
   "source": [
    "adjacency_lists = model.get_hidden_graphs_adjacency_list()\n",
    "\n",
    "# Print the adjacency lists for each hidden graph\n",
    "for i, adj_list in enumerate(adjacency_lists):\n",
    "    print(f\"Hidden Graph {i}:\")\n",
    "    for node, neighbors in adj_list.items():\n",
    "        print(f\"  Node {node}: {neighbors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAJOR DIFFERENCES START HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph 1:\n",
      "Adjacency List: {0: [2], 1: [2, 4], 2: [0, 1, 3], 3: [2, 4], 4: [1, 3]}\n",
      "Sparse Matrix:\n",
      " [[0 0 1 0 0]\n",
      " [0 0 1 0 1]\n",
      " [1 1 0 1 0]\n",
      " [0 0 1 0 1]\n",
      " [0 1 0 1 0]]\n",
      "Node Features:\n",
      " [[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "Graph 2:\n",
      "Adjacency List: {0: [3, 4], 1: [4], 2: [3], 3: [0, 2, 4], 4: [0, 1, 3]}\n",
      "Sparse Matrix:\n",
      " [[0 0 0 1 1]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 1 0]\n",
      " [1 0 1 0 1]\n",
      " [1 1 0 1 0]]\n",
      "Node Features:\n",
      " [[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "Graph 3:\n",
      "Adjacency List: {0: [1, 3], 1: [0], 2: [4], 3: [0, 4], 4: [2, 3]}\n",
      "Sparse Matrix:\n",
      " [[0 1 0 1 0]\n",
      " [1 0 0 0 0]\n",
      " [0 0 0 0 1]\n",
      " [1 0 0 0 1]\n",
      " [0 0 1 1 0]]\n",
      "Node Features:\n",
      " [[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "Graph 4:\n",
      "Adjacency List: {0: [1], 1: [0, 3], 2: [], 3: [1, 4], 4: [3]}\n",
      "Sparse Matrix:\n",
      " [[0 1 0 0 0]\n",
      " [1 0 0 1 0]\n",
      " [0 0 0 0 0]\n",
      " [0 1 0 0 1]\n",
      " [0 0 0 1 0]]\n",
      "Node Features:\n",
      " [[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "Graph 5:\n",
      "Adjacency List: {0: [3], 1: [4], 2: [], 3: [0], 4: [1]}\n",
      "Sparse Matrix:\n",
      " [[0 0 0 1 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 1 0 0 0]]\n",
      "Node Features:\n",
      " [[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "Graph 6:\n",
      "Adjacency List: {0: [4], 1: [2], 2: [1, 3], 3: [2], 4: [0]}\n",
      "Sparse Matrix:\n",
      " [[0 0 0 0 1]\n",
      " [0 0 1 0 0]\n",
      " [0 1 0 1 0]\n",
      " [0 0 1 0 0]\n",
      " [1 0 0 0 0]]\n",
      "Node Features:\n",
      " [[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "Graph 7:\n",
      "Adjacency List: {0: [], 1: [2, 4], 2: [1], 3: [], 4: [1]}\n",
      "Sparse Matrix:\n",
      " [[0 0 0 0 0]\n",
      " [0 0 1 0 1]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 1 0 0 0]]\n",
      "Node Features:\n",
      " [[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "Graph 8:\n",
      "Adjacency List: {0: [2, 3], 1: [3], 2: [0], 3: [0, 1, 4], 4: [3]}\n",
      "Sparse Matrix:\n",
      " [[0 0 1 1 0]\n",
      " [0 0 0 1 0]\n",
      " [1 0 0 0 0]\n",
      " [1 1 0 0 1]\n",
      " [0 0 0 1 0]]\n",
      "Node Features:\n",
      " [[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "Graph 9:\n",
      "Adjacency List: {0: [], 1: [], 2: [], 3: [4], 4: [3]}\n",
      "Sparse Matrix:\n",
      " [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 1 0]]\n",
      "Node Features:\n",
      " [[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "Graph 10:\n",
      "Adjacency List: {0: [2, 3], 1: [2], 2: [0, 1, 3], 3: [0, 2], 4: []}\n",
      "Sparse Matrix:\n",
      " [[0 0 1 1 0]\n",
      " [0 0 1 0 0]\n",
      " [1 1 0 1 0]\n",
      " [1 0 1 0 0]\n",
      " [0 0 0 0 0]]\n",
      "Node Features:\n",
      " [[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "Graph 11:\n",
      "Adjacency List: {0: [1, 2], 1: [0, 2, 3], 2: [0, 1, 3, 4], 3: [1, 2, 4], 4: [2, 3]}\n",
      "Sparse Matrix:\n",
      " [[0 1 1 0 0]\n",
      " [1 0 1 1 0]\n",
      " [1 1 0 1 1]\n",
      " [0 1 1 0 1]\n",
      " [0 0 1 1 0]]\n",
      "Node Features:\n",
      " [[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "Graph 12:\n",
      "Adjacency List: {0: [1, 2, 3], 1: [0, 2, 3], 2: [0, 1, 4], 3: [0, 1, 4], 4: [2, 3]}\n",
      "Sparse Matrix:\n",
      " [[0 1 1 1 0]\n",
      " [1 0 1 1 0]\n",
      " [1 1 0 0 1]\n",
      " [1 1 0 0 1]\n",
      " [0 0 1 1 0]]\n",
      "Node Features:\n",
      " [[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "Graph 13:\n",
      "Adjacency List: {0: [1, 3], 1: [0, 3], 2: [4], 3: [0, 1], 4: [2]}\n",
      "Sparse Matrix:\n",
      " [[0 1 0 1 0]\n",
      " [1 0 0 1 0]\n",
      " [0 0 0 0 1]\n",
      " [1 1 0 0 0]\n",
      " [0 0 1 0 0]]\n",
      "Node Features:\n",
      " [[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "Graph 14:\n",
      "Adjacency List: {0: [2, 3], 1: [4], 2: [0, 3], 3: [0, 2], 4: [1]}\n",
      "Sparse Matrix:\n",
      " [[0 0 1 1 0]\n",
      " [0 0 0 0 1]\n",
      " [1 0 0 1 0]\n",
      " [1 0 1 0 0]\n",
      " [0 1 0 0 0]]\n",
      "Node Features:\n",
      " [[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "Graph 15:\n",
      "Adjacency List: {0: [2, 3], 1: [3], 2: [0, 3, 4], 3: [0, 1, 2], 4: [2]}\n",
      "Sparse Matrix:\n",
      " [[0 0 1 1 0]\n",
      " [0 0 0 1 0]\n",
      " [1 0 0 1 1]\n",
      " [1 1 1 0 0]\n",
      " [0 0 1 0 0]]\n",
      "Node Features:\n",
      " [[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "Graph 16:\n",
      "Adjacency List: {0: [1, 3, 4], 1: [0, 4], 2: [], 3: [0], 4: [0, 1]}\n",
      "Sparse Matrix:\n",
      " [[0 1 0 1 1]\n",
      " [1 0 0 0 1]\n",
      " [0 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [1 1 0 0 0]]\n",
      "Node Features:\n",
      " [[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "import networkx as nx\n",
    "adjacency_lists = model.get_hidden_graphs_adjacency_list()\n",
    "\n",
    "# able to get the feature and adj list of each hidden graph \n",
    "# cuz that's what feeds into the vgae\n",
    "\n",
    "# Print the adjacency lists for each hidden graph\n",
    "for i, adj_list in enumerate(adjacency_lists):\n",
    "     # Create a NetworkX graph from the adjacency list\n",
    "    graph = nx.from_dict_of_lists(adj_list)\n",
    "    \n",
    "    # Convert the NetworkX graph into a sparse adjacency matrix\n",
    "    adj_sparse = nx.adjacency_matrix(graph)\n",
    "    \n",
    "    # Print the sparse matrix (for debugging or visualization)\n",
    "    print(f\"Graph {i + 1}:\")\n",
    "    print(\"Adjacency List:\", adj_list)\n",
    "    print(\"Sparse Matrix:\\n\", adj_sparse.todense())  # Use `todense()` for visualization\n",
    "\n",
    "    # Optionally: Create dummy features (identity matrix)\n",
    "    num_nodes = adj_sparse.shape[0]\n",
    "    features = sp.identity(num_nodes).tolil()\n",
    "    print(\"Node Features:\\n\", features.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAGE PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "from input_data import load_data\n",
    "from preprocessing import preprocess_graph\n",
    "import vgae_model\n",
    "from types import SimpleNamespace\n",
    "\n",
    "vgae_args = SimpleNamespace(\n",
    "    ### CONFIGS ###\n",
    "    model = 'VGAE',\n",
    "    input_dim = 5, \n",
    "    hidden1_dim = 4,\n",
    "    hidden2_dim = 4,\n",
    "    use_feature = True,\n",
    "    num_epoch = 200,\n",
    "    learning_rate = 0.01\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_to_tuple(sparse_mx):\n",
    "    if not sp.isspmatrix_coo(sparse_mx):\n",
    "        sparse_mx = sparse_mx.tocoo()\n",
    "    coords = np.vstack((sparse_mx.row, sparse_mx.col)).transpose()\n",
    "    values = sparse_mx.data\n",
    "    shape = sparse_mx.shape\n",
    "    return coords, values, shape\n",
    "def mask_test_edges(adj):\n",
    "    adj = adj - sp.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape)\n",
    "    adj.eliminate_zeros()\n",
    "\n",
    "    adj_triu = sp.triu(adj)\n",
    "    adj_tuple = sparse_to_tuple(adj_triu)\n",
    "    edges = adj_tuple[0]\n",
    "\n",
    "    num_edges = edges.shape[0]\n",
    "    if num_edges < 10:\n",
    "        print(\"Not enough edges for a split. Using all edges for training.\")\n",
    "        return edges, [], []  # Return all edges for training, no validation/test\n",
    "\n",
    "    num_test = int(np.floor(num_edges / 10.))\n",
    "    num_val = int(np.floor(num_edges / 20.))\n",
    "\n",
    "    all_edge_idx = list(range(num_edges))\n",
    "    np.random.shuffle(all_edge_idx)\n",
    "    val_edge_idx = all_edge_idx[:num_val]\n",
    "    test_edge_idx = all_edge_idx[num_val:(num_val + num_test)]\n",
    "\n",
    "    test_edges = edges[test_edge_idx] if test_edge_idx else []\n",
    "    val_edges = edges[val_edge_idx] if val_edge_idx else []\n",
    "    train_edges = np.delete(edges, np.hstack([test_edge_idx, val_edge_idx]), axis=0)\n",
    "\n",
    "    return train_edges, val_edges, test_edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Adjacency Matrix (without diagonal):\n",
      "   (0, 2)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 4)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 3)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 3)\t1\n",
      "Not enough edges for a split. Using all edges for training.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import networkx as nx\n",
    "import torch  # Add this to check for tensors\n",
    "\n",
    "# Train on CPU (hide GPU) due to memory constraints\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"\"\n",
    "\n",
    "# Get adjacency lists from model\n",
    "# Create graph from the first hidden graph's adjacency list\n",
    "graph = nx.from_dict_of_lists(adjacency_lists[0])\n",
    "\n",
    "# Convert graph to adjacency matrix\n",
    "adj = nx.adjacency_matrix(graph)\n",
    "\n",
    "# Check if adj is a PyTorch tensor and convert it to scipy sparse matrix\n",
    "if isinstance(adj, torch.Tensor):\n",
    "    adj = adj.cpu().numpy()  # Convert tensor to numpy array\n",
    "    adj = sp.coo_matrix(adj)  # Convert numpy array to sparse matrix\n",
    "\n",
    "# Ensure adjacency matrix is sparse (in case it's not already)\n",
    "if not sp.isspmatrix(adj):\n",
    "    adj = sp.coo_matrix(adj)\n",
    "\n",
    "# Generate feature matrix (identity matrix in sparse format)\n",
    "num_nodes = adj.shape[0]\n",
    "features = sp.identity(num_nodes).tolil()\n",
    "\n",
    "# Store original adjacency matrix (without diagonal entries)\n",
    "adj_orig = adj\n",
    "adj_orig = adj_orig - sp.dia_matrix((adj_orig.diagonal()[np.newaxis, :], [0]), shape=adj_orig.shape)\n",
    "adj_orig.eliminate_zeros()\n",
    "\n",
    "print(\"Original Adjacency Matrix (without diagonal):\\n\", adj_orig)\n",
    "\n",
    "# Mask the edges (train/validation/test split)\n",
    "train_edges, val_edges, test_edges = mask_test_edges(adj)\n",
    "\n",
    "# Using the training adjacency matrix\n",
    "adj_train = adj  # Assuming adj_train is returned or defined within mask_test_edges\n",
    "\n",
    "# Ensure adj is in sparse format after edge masking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some preprocessing\n",
    "adj_norm = preprocess_graph(adj)\n",
    "\n",
    "\n",
    "num_nodes = adj.shape[0]\n",
    "\n",
    "features = sparse_to_tuple(features.tocoo())\n",
    "num_features = features[2][1]\n",
    "features_nonzero = features[1].shape[0]\n",
    "\n",
    "# Create Model\n",
    "pos_weight = float(adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum()\n",
    "norm = adj.shape[0] * adj.shape[0] / float((adj.shape[0] * adj.shape[0] - adj.sum()) * 2)\n",
    "\n",
    "\n",
    "adj_label = adj_train + sp.eye(adj_train.shape[0])\n",
    "adj_label = sparse_to_tuple(adj_label)\n",
    "\n",
    "\n",
    "\n",
    "adj_norm = torch.sparse.FloatTensor(torch.LongTensor(adj_norm[0].T), \n",
    "                            torch.FloatTensor(adj_norm[1]), \n",
    "                            torch.Size(adj_norm[2]))\n",
    "adj_label = torch.sparse.FloatTensor(torch.LongTensor(adj_label[0].T), \n",
    "                            torch.FloatTensor(adj_label[1]), \n",
    "                            torch.Size(adj_label[2]))\n",
    "features = torch.sparse.FloatTensor(torch.LongTensor(features[0].T), \n",
    "                            torch.FloatTensor(features[1]), \n",
    "                            torch.Size(features[2]))\n",
    "\n",
    "weight_mask = adj_label.to_dense().view(-1) == 1\n",
    "weight_tensor = torch.ones(weight_mask.size(0)) \n",
    "weight_tensor[weight_mask] = pos_weight\n",
    "\n",
    "# init model and optimizer\n",
    "model = getattr(vgae_model,vgae_args.model)(adj_norm)\n",
    "optimizer = Adam(model.parameters(), lr=vgae_args.learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_scores(edges_pos, edges_neg, adj_rec):\n",
    "\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    # Predict on test set of edges\n",
    "    preds = []\n",
    "    pos = []\n",
    "    for e in edges_pos:\n",
    "        # print(e)\n",
    "        # print(adj_rec[e[0], e[1]])\n",
    "        preds.append(sigmoid(adj_rec[e[0], e[1]].item()))\n",
    "        pos.append(adj_orig[e[0], e[1]])\n",
    "\n",
    "    preds_neg = []\n",
    "    neg = []\n",
    "    for e in edges_neg:\n",
    "\n",
    "        preds_neg.append(sigmoid(adj_rec[e[0], e[1]].data))\n",
    "        neg.append(adj_orig[e[0], e[1]])\n",
    "\n",
    "    preds_all = np.hstack([preds, preds_neg])\n",
    "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n",
    "    roc_score = roc_auc_score(labels_all, preds_all)\n",
    "    ap_score = average_precision_score(labels_all, preds_all)\n",
    "\n",
    "    return roc_score, ap_score\n",
    "\n",
    "def get_acc(adj_rec, adj_label):\n",
    "    labels_all = adj_label.to_dense().view(-1).long()\n",
    "    preds_all = (adj_rec > 0.5).view(-1).long()\n",
    "    accuracy = (preds_all == labels_all).sum().float() / labels_all.size(0)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5])\n"
     ]
    }
   ],
   "source": [
    "# Initialize VGAE model with the adjacency matrix\n",
    "adj_dense = torch.tensor(adj.toarray(), dtype=torch.float32)  # Ensure it's a tensor\n",
    "\n",
    "model = vgae_model.VGAE(adj_dense)  # Make sure to pass the adjacency matrix during initialization\n",
    "print(features.shape)\n",
    "# Training loop\n",
    "for epoch in range(vgae_args.num_epoch):\n",
    "    t = time.time()\n",
    "\n",
    "    # Pass the features to the model\n",
    "    A_pred = model(features)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = log_lik = norm * F.binary_cross_entropy(A_pred.view(-1), adj_label.to_dense().view(-1), weight=weight_tensor)\n",
    "    \n",
    "    if vgae_args.model == 'VGAE':\n",
    "        # KL divergence regularization\n",
    "        kl_divergence = 0.5 / A_pred.size(0) * (1 + 2 * model.logstd - model.mean**2 - torch.exp(model.logstd)**2).sum(1).mean()\n",
    "        loss -= kl_divergence\n",
    "\n",
    "    # Backpropagate and optimize\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Compute train accuracy\n",
    "    train_acc = get_acc(A_pred, adj_label)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    # val_roc, val_ap = get_scores(val_edges, val_edges_false, A_pred)\n",
    "    \n",
    "    # # Print training stats\n",
    "    # print(f\"Epoch: {epoch + 1:04d} train_loss={loss.item():.5f} train_acc={train_acc:.5f} \"\n",
    "    #       f\"val_roc={val_roc:.5f} val_ap={val_ap:.5f} time={time.time() - t:.5f}\")\n",
    "\n",
    "# # Evaluate on test set after training\n",
    "# test_roc, test_ap = get_scores(test_edges, test_edges_false, A_pred)\n",
    "# print(f\"End of training! test_roc={test_roc:.5f} test_ap={test_ap:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get latent embeddings (mean and log standard deviation)\n",
    "z_mean = model.mean\n",
    "z_log_std = model.logstd\n",
    "\n",
    "# Sample latent variables from the Gaussian distribution\n",
    "z_sampled = z_mean + torch.randn_like(z_log_std) * torch.exp(z_log_std)\n",
    "# Decode the sampled latent variables to generate a new adjacency matrix\n",
    "new_adj_rec = torch.sigmoid(torch.matmul(z_sampled, z_sampled.t()))\n",
    "# Generate binary adjacency matrix (threshold the probabilities)\n",
    "threshold = 0.5  # Adjust the threshold as needed\n",
    "new_adj_binary = (new_adj_rec > threshold).float()\n",
    "new_adj_sparse = sp.coo_matrix(new_adj_binary.detach().cpu().numpy())\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a graph from the adjacency matrix\n",
    "G = nx.from_scipy_sparse_matrix(new_adj_sparse)\n",
    "\n",
    "# Visualize the graph\n",
    "nx.draw(G, with_labels=True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleAttributeError",
     "evalue": "'VGAE' object has no attribute 'get_hidden_graphs_adjacency_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-95b909a1c9c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Assuming model is defined and adjacency lists are obtained as follows:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0madjacency_lists\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_hidden_graphs_adjacency_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Draw the adjacency list as a graph using NetworkX and Matplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\richa\\Desktop\\CodingWorkspaces\\hrwgnn\\36venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    777\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[1;32m--> 779\u001b[1;33m             type(self).__name__, name))\n\u001b[0m\u001b[0;32m    780\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Module'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleAttributeError\u001b[0m: 'VGAE' object has no attribute 'get_hidden_graphs_adjacency_list'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "# Assuming model is defined and adjacency lists are obtained as follows:\n",
    "adjacency_lists = model.get_hidden_graphs_adjacency_list()\n",
    "\n",
    "# Draw the adjacency list as a graph using NetworkX and Matplotlib\n",
    "for i, adj_list in enumerate(adjacency_lists):\n",
    "    G = nx.Graph()  # Create a new graph\n",
    "    # Add edges to the graph based on the adjacency list\n",
    "    for node, neighbors in adj_list.items():\n",
    "        for neighbor in neighbors:\n",
    "            G.add_edge(node, neighbor)\n",
    "\n",
    "    # Draw the graph\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    pos = nx.spring_layout(G)  # Positioning the nodes using the spring layout\n",
    "    nx.draw(G, pos, with_labels=True, node_size=500, node_color='skyblue', font_size=10, font_weight='bold', edge_color='gray')\n",
    "    plt.title(f\"Hidden Graph {i}\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "36venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
